{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPq7jGc8QTKnCTwyByOOCUj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#COSE474-202F: Deep Learning HW1\n","#####note by : 슈하다 2022320107"],"metadata":{"id":"XGJX6Z4yUVi7"}},{"cell_type":"markdown","source":["## 0.1 Installation"],"metadata":{"id":"E4gn9aA9VaiT"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"AAP_bsa2UCuX"},"outputs":[],"source":["pip install torch==2.0.0 torchvision==0.15.1"]},{"cell_type":"code","source":["pip install d2l==1.0.3"],"metadata":{"collapsed":true,"id":"a4ahgPWRWARJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##2.1 Data Manipulation\n","###2.1.1 Getting Started"],"metadata":{"id":"u5YafaQ2X7KB"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"wUpjaoznWtUP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.arange(12, dtype=torch.float32)\n","x"],"metadata":{"id":"qL7x7nQHYn4C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x.numel()"],"metadata":{"id":"plMSV2aPaDNg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x.shape"],"metadata":{"id":"9oLoOITmaLce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = x.reshape(3,4)\n","X"],"metadata":{"id":"B_QTyVeCaQDX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.zeros((2,3,4))"],"metadata":{"id":"tfb3M9_Jaa7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.ones((2,3,4))"],"metadata":{"id":"GAD4_MPZa0Ws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.randn(3,4)"],"metadata":{"id":"FeTn-Sg-a4OU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.tensor([[2,1,4,3], [1,2,3,4], [4,3,2,1]])"],"metadata":{"id":"t881lxGxbA2r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2.1.2 Indexing and Slicing"],"metadata":{"id":"zQFUoj-ecKD1"}},{"cell_type":"code","source":["X[-1], X[1:3]"],"metadata":{"id":"9O3UPye1bMi1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X[1,2] = 17\n","X"],"metadata":{"id":"kt_Xq8ERdwNT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X[:2, :] = 12\n","X"],"metadata":{"id":"JHH2YSLXe6Xj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2.1.3 Operations"],"metadata":{"id":"Nvk570a3iDce"}},{"cell_type":"code","source":["torch.exp(x)"],"metadata":{"id":"kD-yxcNZiBx4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.tensor([1.0, 2, 4, 8])\n","y = torch.tensor([2, 2, 2, 2])\n","x + y, x - y, x * y, x / y,x ** y"],"metadata":{"id":"Rv3aia9Mm-tp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n","Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n","torch.cat((X,Y), dim=0), torch.cat((X, Y), dim=1)"],"metadata":{"id":"pR559utGnm5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X == Y"],"metadata":{"id":"6cr1pYThog56"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.sum()"],"metadata":{"id":"U4ipxtuWorbZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2.1.4 Broadcasting"],"metadata":{"id":"75oXH2Xqoym3"}},{"cell_type":"code","source":["a = torch.arange(3).reshape((3,1))\n","b = torch.arange(2).reshape((1,2))\n","a, b"],"metadata":{"id":"sMwarAFxovSG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a + b"],"metadata":{"id":"eYdEI3hyp-6_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2.1.5 Saving Memory"],"metadata":{"id":"BRtC605PqFnf"}},{"cell_type":"code","source":["before = id(Y)\n","Y = Y + X\n","id(Y) == before"],"metadata":{"id":"INrS-XtOqEOQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Z = torch.zeros_like(Y)\n","print('id(Z):', id(Z))\n","Z[:] = X + Y\n","print('id(Z):', id(Z))"],"metadata":{"id":"-p5t8c48qZcZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["before = id(X)\n","X += Y\n","id(X) == before"],"metadata":{"id":"66FlJWj8qz5c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2.1.6 Conversion to Other Pyhton Objects"],"metadata":{"id":"_Zs6eRIqq9Om"}},{"cell_type":"code","source":["A = X.numpy()\n","B = torch.from_numpy(A)\n","type(A), type(B)"],"metadata":{"id":"o-Qvk3Mxq783"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = torch.tensor([3.5])\n","a, a.item(), float(a), int(a)"],"metadata":{"id":"AW0vBfzarOT4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Discussion & Exercises [ 2.1 ]"],"metadata":{"id":"u74aj21wroqf"}},{"cell_type":"markdown","source":["\n","1. Data Handling Basics\n","  - To work with data, two main step are crucial: acquiring the data and processing it\n","  - Data must be stored before processing, making data storage a foundational task.\n","2. Dimensional Arrays (Tensors)\n","  - Mutidimensional arrays are referred to as *tensors*\n","  - Tensors are essential for storing and manipulating data effeciently.\n","  - Unlike Numpy, which operrtaes on CPUs, tensors in deep learning frameworks can leverage GPUs to accelerate numerical computations, making them ideal for large-scale machine learning tasks.\n","\n","\n"],"metadata":{"id":"SYsyfKYWwxtP"}},{"cell_type":"markdown","source":["2.1.1\n","\n","PyTorch Tensor Basics\n","\n","1. Creating Tensors\n","  - Arange : Create a tensor of evently spaced values, `[x = torch.arange(n, dtype)]`\n","  - Zeros/Ones : Create tensors filled with 0s or 1s, `[torch.zeros((n,n,n))] , [torch.ones((n,n,n))]`\n","  - Random Values : Create tensors with values sampled from a standard normal distribution, `[torch.rand(n,n)]`\n","2. Inspecting Tensors\n","  - Number of Elements: `x.numel()` returns the number of elements\n","  - Shape : `x.shape` returns the shape of the tensor\n","3. Reshaping Tensors\n","  - Reshape without changing data using `reshape()`. Can automatically infer one dimension by using -1.\n","\n","\n","```\n","# Example\n","x.reshape(3,4) # Reshape into 3x4 matrix\n","x.reshape(-1,4) # Automatically infers the first dimension\n","```\n","4. Custom Tensors : Can manually create tensors by passing lists, `[torch.tensor()]`\n","\n"],"metadata":{"id":"7lGQVrI6zw9x"}},{"cell_type":"markdown","source":["2.1.2\n","\n","Indexing and Slicing Tensors in PyTorch\n","\n","  1. Basic Indexing\n","    - Access individual elements using indices(starting from 0)\n","    - Negative Indexing : Access elements from the end using negative indices\n","    \n","    `X[-1] # Last row of tensor`\n","    \n","    `X[1:3] # Second and third rows`\n","\n","  2. Slicing\n","    - Use slicing to access ranges\n","\n","    `X[start:stop]` (includes `start`, excludes `stop`)\n","  3. Modifying Elements\n","    - Assign values to specific tensor elements using their indices.\n","\n","    `X[1,2] = 17 # Sets the element at row 1, column 2 to 17`\n","  4. Assigning Values to Multiple Elements\n","    - Index multiple elements and assign the same value to them\n","\n","    `X[:2, :] = 12 # Sets all the elements in the first two rows to 12`\n","\n"],"metadata":{"id":"C_gt9VeB4zLz"}},{"cell_type":"markdown","source":["2.1.3\n","\n","Tensor Operations in PyTorch\n","\n","  1. Elementwise Operations\n","    - Apply scalar operations to each element of the tensor\n","\n","    `torch.exp(x) # Elementwise exponential function `\n","\n","    - Binary operations (addition, substraction, etc.) work elementwise for tensors of the same shape.\n","\n","  2. Concatenation\n","  \n","    - Combine tensors along a specified axis using `torch.cat()`.\n","\n","      - `dim=0` : Concatenate along rows\n","      - `dim=1 `: Concatenate along columns\n","\n","  3. Logical Operations\n","\n","    - Create a binary tensor using logical comparison that returns a tensor of True/False, e.g., `X == Y`.\n","\n","  4. Summing Tensor Elements\n","\n","    - Sum all elements in a tensor using `X.sum()`, resulting in a scalar value."],"metadata":{"id":"y-qqSPe18lo_"}},{"cell_type":"markdown","source":["2.1.4\n","\n","Broadcasting in PyTorch\n","\n","  - Broadcasting allows elementwise operations on tensors with different shapes by automatically expanding one or both tensors.\n","\n","  - Steps in Broadcasting:\n","\n","   1. Expand the smaller tensor(s) by copying elements along axes with length 1 to match the shape of the larger tensor.\n","   2. Perform the elementwise operation on the resulting arrays.\n","\n","  - Example :\n","    - a is a (3,1) tensor, and b is a (1,2) tensor.\n","    - Broadcasting expands a along the columns and b along the rows to create compatible shapes."],"metadata":{"id":"bp3QhHbS_Zzx"}},{"cell_type":"markdown","source":["2.1.5\n","\n","Saving Memory in PyTorch\n","\n","  - Memory Allocation in Operations\n","    - Running operations like `Y = Y + X ` creates new memory to store the result and reassigns Y to the new memory location, which can be inefficient.\n","  \n","  - In-Place Operations\n","    - To avoid unnecessary memory allocation and maintain references, use in-place operations with slice notation or augmented assignment (+=), e.g., `X += Y`."],"metadata":{"id":"gcLDzezoBTSI"}},{"cell_type":"markdown","source":["2.1.6\n","\n","Conversion Between PyTorch Tensors and Other Python Objects\n","\n","  - Converting is straightforward, and resulting PyTorch tensor and Numpy array share the same underlying memory. Changes in one will affect the other.\n","\n","  - Converting a Size-1 Tensor to a Python Scalar\n","    - Use the `item()` method or Python's built-in functions to convert a single-element tensor to a scalar."],"metadata":{"id":"x3xxvG42DPGb"}},{"cell_type":"markdown","source":["###Exercises\n","1. Run the code in this section. Change the conditional statement X == Y to X < Y or X > Y, and then see what kind of tensor you can get."],"metadata":{"id":"wjjjdMtHEw4h"}},{"cell_type":"code","source":["X = torch.arange(15).reshape(5,3)"],"metadata":{"id":"X2zDKX7OrYCD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y = torch.arange(15, 0, -1).reshape(5,3)"],"metadata":{"id":"MQ1mw_vzFWuu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X == Y, X > Y, X < Y"],"metadata":{"id":"srA_epVyFcJb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Replace the two tensors that operate by element in the broadcasting mechanism with other shapes, e.g., 3-dimensional tensors. Is the result the same as expected?"],"metadata":{"id":"ZM1oClTWFsji"}},{"cell_type":"code","source":["X = torch.arange(8).reshape(4, 2, 1)"],"metadata":{"id":"DuXZdV41FgaZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y = torch.arange(8).reshape(1, 2, 4)"],"metadata":{"id":"Qy_COUbNGB5t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"{X}, \\n\\n\\n{Y}, \\n\\n\\n{X + Y}\")"],"metadata":{"id":"xnRiQfU6GGfe"},"execution_count":null,"outputs":[]}]}